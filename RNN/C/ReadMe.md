#### RNN
* 1 hidden layer
* tanh() hidden node
* softmax() output node

#### Note
* Input and output should be one-hot vector

#### TODO
* Dynamic learning rate
* Gradient check

#### Reference
* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-2-implementing-a-language-model-rnn-with-python-numpy-and-theano/